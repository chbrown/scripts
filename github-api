#!/usr/bin/env python
import re
import os
import sys
import json
import urllib
import logging
import argparse
import requests


logger = logging.getLogger('github-api')


def remove_urls(x):
    '''
    Remove keys ending with 'url' from `x`, recursing into dicts and lists.
    '''
    if isinstance(x, dict):
        return dict((k, remove_urls(v)) for k, v in x.items() if not k.endswith('url'))
    elif isinstance(x, list):
        return [remove_urls(y) for y in x]
    return x


class CustomJSONEncoder(json.JSONEncoder):
    def default(self, o):
        if isinstance(o, requests.models.CaseInsensitiveDict):
            return dict(o.items())
        return json.JSONEncoder.default(self, o)

    def print(self, o, file=sys.stdout, flush=True):
        print(self.encode(o), file=file, flush=flush)


def prepare_url(url):
    '''
    Prefix `url` with the API root if it does not already start with it.
    '''
    return urllib.parse.urljoin('https://api.github.com/', url)


def request(url, method='GET', headers=None, params=None):
    '''
    Perform generic GitHub API request, printing results to stdout.
    '''
    logger.debug('Requesting URL: %s', url)
    response = requests.request(method, url, headers=headers, params=params)

    # only pretty-print if stdout is a TTY (not piped anywhere else)
    indent = 2 if sys.stdout.isatty() else None
    encoder = CustomJSONEncoder(ensure_ascii=False, sort_keys=True, indent=indent)

    logger.info('response headers: %s', response.headers)

    result = response.json()
    result = remove_urls(result)

    if isinstance(result, dict):
        encoder.print(result)
    else:
        for item in result:
            encoder.print(item)
    return response


def _parse_links(links_string):
    '''
    Parse a header string like: (the newline should be just a single space)
    '<https://api.github.com/repositories/12345/commits?page=2>; rel="next",
     <https://api.github.com/repositories/12345/commits?page=5>; rel="last"'
    into a key-value pairs with these possible keys: next, last, first, prev
    '''
    # The filter(None, ...) handles the case where links_string is the empty string
    for link_string in filter(None, re.split(r',\s*', links_string)):
        href_string, rel_string = re.split(r';\s*', link_string)
        href_match = re.match(r'<(.+)>', href_string)
        rel_match = re.match(r'rel="(.+)"', rel_string)
        yield rel_match.group(1), href_match.group(1)


def commits(owner, repo, headers=None):
    path = '/repos/{owner}/{repo}/commits'.format(owner=owner, repo=repo)
    response = request(prepare_url(path), headers=headers, params={'per_page': 100})
    links = dict(_parse_links(response.headers.get('Link', '')))
    # if there's only one page of commits, there won't be a rel="last" link
    if 'last' in links:
        logger.info('...')
        request(links['last'], headers=headers)


def contents(owner, repo, path, headers=None, params=None):
    path = '/repos/{owner}/{repo}/contents/{path}'.format(owner=owner, repo=repo, path=path)
    request(prepare_url(path), headers=headers, params=params)


### CLI command funcs

def path_command(opts, headers):
    request(prepare_url(opts.path), headers=headers)

def commits_command(opts, headers):
    commits(opts.owner, opts.repo, headers=headers)

def contents_command(opts, headers):
    contents(opts.owner, opts.repo, opts.path, headers=headers)

def main():
    parser = argparse.ArgumentParser(
        description='Execute GitHub API requests',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('-t', '--token', default=os.environ.get('GITHUB_TOKEN'),
                        help='authorization token')
    parser.add_argument('-v', '--verbose', action='count', default=0,
                        help='log extra information (repeat for even more)')

    subparsers = parser.add_subparsers(dest='subcommand',
                                       help='special-purpose subcommands')

    # TODO: implement a default subcommand of nothing, somehow (argparse fail)
    # see: https://stackoverflow.com/q/6365601
    parser_path = subparsers.add_parser('path')
    parser_path.add_argument('path', help='API path; e.g., "/user"')
    parser_path.set_defaults(func=path_command)

    parser_commits = subparsers.add_parser('commits')
    parser_commits.add_argument('--owner', help='repository owner (user/organization)')
    parser_commits.add_argument('--repo', help='repository name')
    parser_commits.set_defaults(func=commits_command)

    parser_contents = subparsers.add_parser('contents')
    parser_contents.add_argument('--owner', help='repository owner (user/organization)')
    parser_contents.add_argument('--repo', help='repository name')
    parser_contents.add_argument('--path', help='path in repository to list contents of')
    parser_contents.set_defaults(func=contents_command)

    opts = parser.parse_args()

    loglevel = 30 - (opts.verbose * 10)
    # (none) = 0 => WARNING = 30, -v = 1 => INFO = 20, -vv = 2 => DEBUG = 10, -vvv = 3 => NOTSET = 0
    logging.basicConfig(level=loglevel)
    logger.debug('Logging at level %d', loglevel)

    headers = {'Accept': 'application/vnd.github.v3+json'}
    if opts.token:
        headers['Authorization'] = 'token {}'.format(opts.token)
        logger.info('Using token: %s...', opts.token[:7])
    else:
        logger.warning('Could not find token; continuing without authentication.')

    opts.func(opts, headers)


if __name__ == '__main__':
    main()
